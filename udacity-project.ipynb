{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity ML Azure, Project 1: Optimizing a Machine Learning Pipeline\n",
    "\n",
    "Here means of optimizating machine learning pipelines are trialled and compared.\n",
    "* 1. Hyperdrive: Build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.\n",
    "* 2. Azure AutoML.\n",
    "\n",
    "The results of these two approaches are compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598275788035
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "\n",
    "# Note: this requires the workspace name to be known at the point of editing this notebook:\n",
    "#ws = Workspace.get(name=\"udacity-project\")\n",
    "\n",
    "# An alternative approach is to use the \"ws = Workspace.from_config()\" method.\n",
    "# This fetches the workspace details from the config file created by Azure when the session starts.\n",
    "# https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.workspace.workspace?view=azure-ml-py\n",
    "ws = Workspace.from_config()\n",
    "exp = Experiment(workspace=ws, name=\"udacity-project\")\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "run = exp.start_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperdrive\n",
    "## 1. Create a compute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598275788675
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException  # Use when verifying whether cluster already exists\n",
    "\n",
    "# TODO: Create compute cluster\n",
    "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\n",
    "# max_nodes should be no greater than 4.\n",
    "\n",
    "# Useful refs for verifying whether cluster exists and provisioning a compute cluster:\n",
    "# https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.compute.computetarget?view=azure-ml-py\n",
    "# https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/training/train-on-amlcompute/train-on-amlcompute.ipynb\n",
    "\n",
    "# Set the compute cluster name\n",
    "cluster_name = \"azml-cluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "# If cluster already exists use it, otherwise initialize the cluster (exception thrown if cluster does not exist)\n",
    "try:\n",
    "    azml_cluster = ComputeTarget(ws, cluster_name)  # exists\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # Set up the compute cluster config\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size = \"Standard_D2_V2\", max_nodes = 4)\n",
    "    # Create the compute cluster\n",
    "    azml_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "# Wait for the current provisioning operation to finish on the cluster.\n",
    "azml_cluster.wait_for_completion(show_output = True)\n",
    "\n",
    "# Display status information about the AmlCompute target:\n",
    "# Fetch AmlComputeStatus object using ComputeTarget's get_status() method\n",
    "# AmlComputeStatus: Represents detailed status information about an AmlCompute target.\n",
    "# Convert the AmlComputeStatus object into a JSON serialized dictionary using serialize().\n",
    "# Ref: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.compute.amlcompute.amlcomputestatus\n",
    "print(azml_cluster.get_status().serialize())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up the Hyperdrive configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598275789986
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform, choice\n",
    "import os\n",
    "\n",
    "# Specify parameter sampler\n",
    "# https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.randomparametersampling\n",
    "param_dict = {\n",
    "    \"--C\" : uniform(0.001, 2.0),\n",
    "    \"--max_iter\" : choice(10,25,50,100,150,200,250)\n",
    "}\n",
    "ps = RandomParameterSampling(param_dict)\n",
    "\n",
    "# Specify a Policy\n",
    "# https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.banditpolicy\n",
    "policy = BanditPolicy(evaluation_interval=5, slack_factor=0.2)\n",
    "\n",
    "if \"training\" not in os.listdir():\n",
    "    os.mkdir(\"./training\")\n",
    "\n",
    "# Create a SKLearn estimator for use with train.py\n",
    "# https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.sklearn.sklearn\n",
    "est = SKLearn(source_directory=\".\",\n",
    "              compute_target=azml_cluster, \n",
    "              vm_size=\"Standard_D2_V2\", \n",
    "              vm_priority=\"dedicated\", \n",
    "              entry_script=\"train.py\")\n",
    "\n",
    "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
    "# https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.hyperdriveconfig\n",
    "hyperdrive_config = HyperDriveConfig(hyperparameter_sampler=ps, \n",
    "                                     primary_metric_name=\"Accuracy\", \n",
    "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
    "                                     policy=policy, \n",
    "                                     estimator=est,\n",
    "                                     max_total_runs=16,\n",
    "                                     max_concurrent_runs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Submit Hyperdrive run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit your hyperdrive run to the experiment and show run details with the widget.\n",
    "hd_run = exp.submit(hyperdrive_config)\n",
    "RunDetails(hd_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_run.wait_for_completion(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get the best Hyperdrive run and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598276310862
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "# Get your best run and save the model from that run.\n",
    "best_run = hd_run.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "\n",
    "# Implementation for saving the model guided by information here:\n",
    "# https://knowledge.udacity.com/questions/424266\n",
    "# https://github.com/Azure/MachineLearningNotebooks/blob/a039166b901b90b6fa5a364c728aca7936e3789d/how-to-use-azureml/ml-frameworks/scikit-learn/train-hyperparameter-tune-deploy-with-sklearn/train-hyperparameter-tune-deploy-with-sklearn.ipynb\n",
    "# Download the model from the best run\n",
    "print(\"Filenames:\",best_run.get_file_names()) # print the filenames\n",
    "print(\"Run Details:\",best_run.get_details()['runDefinitions']['arguments']) # print the run details\n",
    "best_run.download_file(best_run.get_file_names()[-1], output_file_path='./outputs/')\n",
    "\n",
    "print(\"Best Run ID:\",best_run.id)\n",
    "print(\"Accuracy:\",best_run_metrics[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that best model has been retrieved\n",
    "joblib.load('./outputs/my_model.joblib')\n",
    "\n",
    "# Register the model\n",
    "best_hyperdrive_model = best_run.register_model(\n",
    "    model_name=\"best_hyperdrive_model\",\n",
    "    model_path=\"./outputs/my_model.joblib\",\n",
    "    tags=best_run.get_metrics()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------------------\n",
    "# AutoML\n",
    "## 1. Read in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "\n",
    "# Create TabularDataset using TabularDatasetFactory\n",
    "# Data is available at: \n",
    "# \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
    "\n",
    "raw_data_url = \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
    "ds = TabularDatasetFactory.from_delimited_files(raw_data_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean the data\n",
    "\n",
    "Clean the data and divide into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598275726969
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from train import clean_data\n",
    "\n",
    "# Use the clean_data function to clean the data.\n",
    "x, y = clean_data(ds)\n",
    "\n",
    "# Split into train and test set\n",
    "# Note: nothing has been specified in the rubric with respect to use of the test set...\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=8, stratify=y)\n",
    "\n",
    "# Training data as DataFrame (joining input and target feature again into one DataFrame)\n",
    "df_train = pd.concat([x_train,y_train], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set the parameters of the AutoMLConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598275665403
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "# Set parameters for AutoMLConfig\n",
    "# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\n",
    "# If you wish to run the experiment longer, you will need to run this notebook in your own\n",
    "# Azure tenant, which will incur personal costs.\n",
    "automl_config = AutoMLConfig(\n",
    "    experiment_timeout_minutes=30,\n",
    "    task='classification',\n",
    "    primary_metric='Accuracy',\n",
    "    training_data=df_train,\n",
    "    label_column_name='y',\n",
    "    n_cross_validations=5,\n",
    "    compute_target=azml_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Submit the AutoML run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Submit your automl run\n",
    "experiment = Experiment(workspace, \"automl_expt\")\n",
    "automl_run = experiment.submit(config=automl_config, show_output=True)\n",
    "# View progress\n",
    "RunDetails(automl_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Retrieve and save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and save your best automl model.\n",
    "best_run, best_model = automl_run.get_output()\n",
    "best_run.register_model(model_name = 'automl_best_model.pkl', model_path = './outputs/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Additional step - test the best AutoML model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "# https://docs.microsoft.com/en-us/azure/machine-learning/tutorial-auto-train-models\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "y_predict = best_model.predict(x_test)\n",
    "y_actual = y_test.values.flatten().tolist()\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_actual, y_predict).ravel()\n",
    "target_names = ['YES', 'NO']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------------------------------------------------------------------------------------------------------------------------------\n",
    "## Clean up deployed resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the compute cluster \n",
    "azml_cluster.delete()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
